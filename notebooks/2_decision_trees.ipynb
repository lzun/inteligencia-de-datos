{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzdEpPeMPdll0h0iYw5Zm6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Práctica 2: Árboles de Decisión\n","\n","Inteligencia de Datos\n","\n","Universidad Iberoamericana Ciudad de México\n","\n","Creado por: Luis Norberto Zúñiga Morales, inspirado en el libro *Hands-On Machine Learning with Scikit-Learn, Keras & Tensorflow*."],"metadata":{"id":"mY0LHuw-MvVC"}},{"cell_type":"markdown","source":["Los árboles de decisión (AD) son modelos muy versátiles que permiten realizar tanto clasificación como regresión. Además, como veremos más adelante, son el bloque fundamental de modelos más complejos, como los Bosques Aleatorios.\n","\n","En esta práctica vamos a explorar como entrenar, visualizar y hacer visualizaciones con AD en scikit-learn. Después, exploraremos como regularizar estos modelos.\n","\n","\n","---\n","\n"],"metadata":{"id":"Dz314OmPDUD7"}},{"cell_type":"markdown","source":["## Entrenamiento y visualización de Árboles de Decisión"],"metadata":{"id":"Zw0jZp-aEVwv"}},{"cell_type":"markdown","source":["Para comprender mejor la idea que permite que los AD funciones, vamos a construir uno de estos modelos y dar un vistazo a las predicciones que realiza. Iniciemos entrenando un `DecisionTreeClassifier` con el conjunto de datos Iris:"],"metadata":{"id":"_ItC49wyFZ91"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","from sklearn.tree import DecisionTreeClassifier\n","\n","iris = load_iris()\n","X = iris.data[:, 2:] # largo y ancho del petalo\n","y = iris.target\n","\n","tree_clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n","tree_clf.fit(X, y)"],"metadata":{"id":"Xx7rAX-9GWGD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Actividad**: Revisen lo documentación de `DecisionTreeClassifier` y expliquen qué es lo que hacen los primeros cinco parámetros de la clase."],"metadata":{"id":"Gql0buJiItsb"}},{"cell_type":"markdown","source":["*Su respuesta en esta celda*"],"metadata":{"id":"P-E0-fnmJY9D"}},{"cell_type":"markdown","source":["¿Cómo se ve el árbol entrenado? Por ver, nos referimos a las decisiones que toma en cada nodo."],"metadata":{"id":"SggRxVABG9ji"}},{"cell_type":"code","source":["from graphviz import Source\n","from sklearn.tree import export_graphviz\n","\n","export_graphviz(\n","        tree_clf,\n","        out_file=\"iris_tree.dot\",\n","        feature_names=iris.feature_names[2:],\n","        class_names=iris.target_names,\n","        rounded=True,\n","        filled=True\n","    )"],"metadata":{"id":"ZhTxSONFHFNV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Source.from_file(\"iris_tree.dot\")"],"metadata":{"id":"xw3YjbhgHt_t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["** Actividad**: Supongan que encuentran una flor Iris, a la cual le sacan sus medidas. ¿Cómo interpretan el árbol anterior para determinar la clase de la nueva flor?"],"metadata":{"id":"UWYXjP_3IOpB"}},{"cell_type":"markdown","source":["*Su respuesta en esta celda*"],"metadata":{"id":"xjw8OzzCIf3L"}},{"cell_type":"markdown","source":["## Predicciones con Árboles de Decisión"],"metadata":{"id":"4C23H9WFJd80"}},{"cell_type":"markdown","source":["Scikit-learn puede usar distintos criterios para medir la calidad de un partición en un nodo. En clase vimos el criterio de entropía y de tarea se dejó investigar el criterio de Gini.\n","\n","A continuación, vamos a graficar cada partición (o decisión) hecha en el árbol."],"metadata":{"id":"k-ARYlQzJiHk"}},{"cell_type":"code","source":["import numpy as np\n","\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)"],"metadata":{"id":"Hhkv2UlVLvIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from matplotlib.colors import ListedColormap\n","\n","def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n","    x1s = np.linspace(axes[0], axes[1], 100)\n","    x2s = np.linspace(axes[2], axes[3], 100)\n","    x1, x2 = np.meshgrid(x1s, x2s)\n","    X_new = np.c_[x1.ravel(), x2.ravel()]\n","    y_pred = clf.predict(X_new).reshape(x1.shape)\n","    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n","    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n","    if not iris:\n","        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n","        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n","    if plot_training:\n","        plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", label=\"Iris setosa\")\n","        plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", label=\"Iris versicolor\")\n","        plt.plot(X[:, 0][y==2], X[:, 1][y==2], \"g^\", label=\"Iris virginica\")\n","        plt.axis(axes)\n","    if iris:\n","        plt.xlabel(\"Largo del pétalo\", fontsize=14)\n","        plt.ylabel(\"Ancho del pétalo\", fontsize=14)\n","    else:\n","        plt.xlabel(r\"$x_1$\", fontsize=18)\n","        plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)\n","    if legend:\n","        plt.legend(loc=\"lower right\", fontsize=14)\n","\n","plt.figure(figsize=(8, 4))\n","plot_decision_boundary(tree_clf, X, y)\n","plt.plot([2.45, 2.45], [0, 3], \"k-\", linewidth=2)\n","plt.plot([2.45, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n","plt.plot([4.95, 4.95], [0, 1.75], \"k:\", linewidth=2)\n","plt.plot([4.85, 4.85], [1.75, 3], \"k:\", linewidth=2)\n","plt.text(1.40, 1.0, \"Depth=0\", fontsize=13)\n","plt.text(3.2, 1.80, \"Depth=1\", fontsize=13)\n","plt.text(4.05, 0.5, \"(Depth=2)\", fontsize=11)\n","\n","plt.show()"],"metadata":{"id":"LhDuFv6qLqV7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["La linea sólida representa el límite de decisión que genera el primer nodo (longitud del pétalo = 2.45 cm). Noten que esta regla separa perfectamente los puntos verdes de los azules, por lo que no se deben crear más particiones, lo cual no sucede en el lado derecho. Por lo tanto, se crea una nueva partición (ancho del pétalo = 1.75 cm) representada por la línea punteada sólida. Dado que usamos el parámetro `max_depth` con un valor de 2, el algoritmo detiene su ejecución en ese punto. Si usaramos un valor de 3, se añadiría otra partición en la parte impura, que es el resultado que se observa con las líneas punteadas más delgadas.\n","\n","Los árboles de decisión son intuitivos y las decisiones son relativamente fáciles de entender. Es decir, son modelos de fácil interpretación (o *cajas blancas*). En contraste, modelo más complejos como las redes neuronales no poseen estas carecterísticas, lo que los vuelven poco interpretables (*cajas negras*)."],"metadata":{"id":"LFz7YneVN54h"}},{"cell_type":"markdown","source":["## Regularización e hiperparámetros"],"metadata":{"id":"C78-_gk60XU2"}},{"cell_type":"markdown","source":["Los árboles de decisión hacen pocas suposiciones sobre los datos de entrenamiento. Si no se controlan, se pueden ajustar demasiado a los datos con los que se entrena, potencialmente ocasionando sobreajuste. Para evitar el sobreajuste se deben restringir algunos parámetros del modelo durante su entrenamiento, es decir, regularizarlo. En este caso, lo que se controla son algunos hiperparámetros del modelo, principalmente la profundida máxima del AD, controlada por el parámetro `max_depth`.\n","\n","Otros parámetros que se deben controlar son:\n","\n","- `min_samples_split`: el número mínimo de muestras que un nodo de contener antes de que se particione.\n","- `min_samples_leaf`: número mínimo de muestras que un nodo debe contener.\n","- `min_weight_fraction_leaf`: igual que el anterior, pero expresado como una fracción del total de instancias ponderadas.\n","- `max_leaf_nodes`: número máximo de nodos hoja.\n","- `max_features`: el número máximo de características que se evaluan para partir cada nodo.\n","\n","Para regularizar, debemos incrementar todos los `min_` o reducir todos los `max_` y encontrar un balance."],"metadata":{"id":"HbGO9MvH0aEu"}},{"cell_type":"markdown","source":["En el siguiente código vamos a crear un conjunto de datos artificial con la función `make_moons` y entrenar dos modelos: el primero sin restricciones y el segundo controloando el parámetro `min_samples_leaf`. Después, vamos a visualizar como particiona el espacio de los datos para comparar su efecto."],"metadata":{"id":"bzaPiayu7mA9"}},{"cell_type":"code","source":["from sklearn.datasets import make_moons\n","Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n","\n","deep_tree_clf1 = DecisionTreeClassifier(random_state=42)\n","deep_tree_clf2 = DecisionTreeClassifier(min_samples_leaf=4, random_state=42)\n","deep_tree_clf1.fit(Xm, ym)\n","deep_tree_clf2.fit(Xm, ym)\n","\n","fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n","plt.sca(axes[0])\n","plot_decision_boundary(deep_tree_clf1, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n","plt.title(\"Sin restricciones\", fontsize=16)\n","plt.sca(axes[1])\n","plot_decision_boundary(deep_tree_clf2, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n","plt.title(\"min_samples_leaf = {}\".format(deep_tree_clf2.min_samples_leaf), fontsize=14)\n","plt.ylabel(\"\")\n","\n","plt.show()"],"metadata":{"id":"CCsBKjk-7Xy-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Actividad**: ¿Qué pueden observar en la gráfica?"],"metadata":{"id":"HARIS4EN76uF"}},{"cell_type":"markdown","source":["*Su respuesta en esta celda*"],"metadata":{"id":"zGEOu_9k8W1D"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8yqsESXEwBA"},"outputs":[],"source":["# Load libraries\n","import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n","from sklearn.model_selection import train_test_split # Import train_test_split function\n","from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"]},{"cell_type":"markdown","source":["## Árboles de Decisión para Regresión"],"metadata":{"id":"QOOB24i98Zu2"}},{"cell_type":"markdown","source":["Como se dejo en la tarea, los árboles de decisión también permiten resolver problemas de regresión. Vamos a implementar un AD usando la clase `DecisionTreeRegressor` en un conjunto de datos cuadrático con ruido. Empezamos creando los datos:"],"metadata":{"id":"AKrxNuxw8gCS"}},{"cell_type":"code","source":["np.random.seed(42)\n","m = 200\n","X = np.random.rand(m, 1)\n","y = 4 * (X - 0.5) ** 2\n","y = y + np.random.randn(m, 1) / 10"],"metadata":{"id":"qJtWrBRc8-Rp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Es turno de crear el modelo de regresión usando AD:"],"metadata":{"id":"007ZSbm-9CWB"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeRegressor\n","\n","tree_reg = DecisionTreeRegressor(max_depth=2, random_state=42)\n","tree_reg.fit(X, y)"],"metadata":{"id":"s5Jf4mM39BwO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Una vez entrenado, vamos a observar las reglas que determinó para particionar los datos:"],"metadata":{"id":"k9tZXGO59VVa"}},{"cell_type":"code","source":["export_graphviz(\n","        tree_reg,\n","        out_file=\"regression_tree.dot\",\n","        feature_names=[\"x1\"],\n","        rounded=True,\n","        filled=True\n","    )\n","\n","Source.from_file( \"regression_tree.dot\")"],"metadata":{"id":"VqqugbfQ9NFL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El AD anterior ahora busca predecir un valor numérico en lugar de una clase. Por ejemplo, si quisieramos determinar el valor de un nuevo dato $x_1=0.6$, empezamos en el nodo de origen, nos vamos al nodo de la derecha, y de ahí al nodo de la izquierda, obteniendo un valor de 0.111. Esta predicción es un promedio de las 110 instancias de entrenamiento asociadas con este nodo hoja y tiene un ECM de 0.015."],"metadata":{"id":"HODU-FbO9l3l"}},{"cell_type":"markdown","source":["¿Cómo particiona ahora un AD para regresión el espacio de los datos? Vamos a verlo en el siguiente ejemplo usando los datos anteriores:"],"metadata":{"id":"8ujuaoXM-UmJ"}},{"cell_type":"code","source":["tree_reg1 = DecisionTreeRegressor(random_state=42, max_depth=2)\n","tree_reg2 = DecisionTreeRegressor(random_state=42, max_depth=3)\n","tree_reg1.fit(X, y)\n","tree_reg2.fit(X, y)\n","\n","def plot_regression_predictions(tree_reg, X, y, axes=[0, 1, -0.2, 1], ylabel=\"$y$\"):\n","    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n","    y_pred = tree_reg.predict(x1)\n","    plt.axis(axes)\n","    plt.xlabel(\"$x_1$\", fontsize=18)\n","    if ylabel:\n","        plt.ylabel(ylabel, fontsize=18, rotation=0)\n","    plt.plot(X, y, \"b.\")\n","    plt.plot(x1, y_pred, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n","\n","fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n","plt.sca(axes[0])\n","plot_regression_predictions(tree_reg1, X, y)\n","for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n","    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n","plt.text(0.21, 0.65, \"Depth=0\", fontsize=15)\n","plt.text(0.01, 0.2, \"Depth=1\", fontsize=13)\n","plt.text(0.65, 0.8, \"Depth=1\", fontsize=13)\n","plt.legend(loc=\"upper center\", fontsize=18)\n","plt.title(\"max_depth=2\", fontsize=14)\n","\n","plt.sca(axes[1])\n","plot_regression_predictions(tree_reg2, X, y, ylabel=None)\n","for split, style in ((0.1973, \"k-\"), (0.0917, \"k--\"), (0.7718, \"k--\")):\n","    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n","for split in (0.0458, 0.1298, 0.2873, 0.9040):\n","    plt.plot([split, split], [-0.2, 1], \"k:\", linewidth=1)\n","plt.text(0.3, 0.5, \"Depth=2\", fontsize=13)\n","plt.title(\"max_depth=3\", fontsize=14)\n","\n","plt.show()"],"metadata":{"id":"7GawQ0-b-RtF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Noten que el valor que predice siempre es un promedio de los datos que se encuentran en cada región. El algoritmo parte cada región de tal manera que elige a los puntos lo más cercanos posible para predecir el valor."],"metadata":{"id":"kKr5rEQd-j6Y"}},{"cell_type":"markdown","source":["Al igual que el caso de clasificación, debemos tener cuidado ya que los AD pueden sobreajustarse a los datos. Por ejemplo, consideren dos modelos, uno sin restricciones, y otro con `min_samples_leaf = 10`."],"metadata":{"id":"tN_gf0yH-3NO"}},{"cell_type":"code","source":["tree_reg1 = DecisionTreeRegressor(random_state=42)\n","tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n","tree_reg1.fit(X, y)\n","tree_reg2.fit(X, y)\n","\n","x1 = np.linspace(0, 1, 500).reshape(-1, 1)\n","y_pred1 = tree_reg1.predict(x1)\n","y_pred2 = tree_reg2.predict(x1)\n","\n","fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n","\n","plt.sca(axes[0])\n","plt.plot(X, y, \"b.\")\n","plt.plot(x1, y_pred1, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n","plt.axis([0, 1, -0.2, 1.1])\n","plt.xlabel(\"$x_1$\", fontsize=18)\n","plt.ylabel(\"$y$\", fontsize=18, rotation=0)\n","plt.legend(loc=\"upper center\", fontsize=18)\n","plt.title(\"Sin restricciones\", fontsize=14)\n","\n","plt.sca(axes[1])\n","plt.plot(X, y, \"b.\")\n","plt.plot(x1, y_pred2, \"r.-\", linewidth=2, label=r\"$\\hat{y}$\")\n","plt.axis([0, 1, -0.2, 1.1])\n","plt.xlabel(\"$x_1$\", fontsize=18)\n","plt.title(\"min_samples_leaf={}\".format(tree_reg2.min_samples_leaf), fontsize=14)\n","\n","plt.show()"],"metadata":{"id":"zA3avyev_UL7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Actividad**: ¿Qué pueden concluir de la gráfica anterior?"],"metadata":{"id":"-RGx29qw_Zd2"}},{"cell_type":"markdown","source":["*Su respuesta en esta celda*"],"metadata":{"id":"z83a1lmg_lQb"}},{"cell_type":"markdown","source":["## Inestabilidad"],"metadata":{"id":"BDxEDfy5_yiH"}},{"cell_type":"markdown","source":["Los AD son un ejemplo de un modelo de aprendizaje que cuenta con un gran balance entre interpretabilidad y versatilidad al momento de usarse. Pero, como todo en la vida, tiene sus limitaciones. Primero, los AD generan límites de decisión ortogonales, lo cual genera problemas si los datos rotan. Por ejemplo, la siguiente gráfica muestra un conjunto de datos linealmente separable que puede ser fácilmente separado por un AD. Sin embargo, si los mismos datos se rotan 45°, el margen de decisión se vuelve muy rebuscado."],"metadata":{"id":"zKteZ-W7_0bQ"}},{"cell_type":"code","source":["np.random.seed(6)\n","Xs = np.random.rand(100, 2) - 0.5\n","ys = (Xs[:, 0] > 0).astype(np.float32) * 2\n","\n","angle = np.pi / 4\n","rotation_matrix = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n","Xsr = Xs.dot(rotation_matrix)\n","\n","tree_clf_s = DecisionTreeClassifier(random_state=42)\n","tree_clf_s.fit(Xs, ys)\n","tree_clf_sr = DecisionTreeClassifier(random_state=42)\n","tree_clf_sr.fit(Xsr, ys)\n","\n","fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n","plt.sca(axes[0])\n","plot_decision_boundary(tree_clf_s, Xs, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n","plt.sca(axes[1])\n","plot_decision_boundary(tree_clf_sr, Xsr, ys, axes=[-0.7, 0.7, -0.7, 0.7], iris=False)\n","plt.ylabel(\"\")\n","\n","plt.show()"],"metadata":{"id":"UwvvRV2EAdcQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Otro defecto que tienen es que, en general, son muy sensibles a pequeñas variaciones de los datos con los que se entrenan. Por ejemplo, si aleatorizamos los datos, obtenemos un modelo distinto al que obtuvimos anteriormente:"],"metadata":{"id":"yt0PwTDPAlxw"}},{"cell_type":"code","source":["X = iris.data[:, 2:] # petal length and width\n","y = iris.target\n","\n","tree_clf_tweaked = DecisionTreeClassifier(max_depth=2, random_state=40)\n","tree_clf_tweaked.fit(X, y)\n","\n","plt.figure(figsize=(8, 4))\n","plot_decision_boundary(tree_clf_tweaked, X, y, legend=False)\n","plt.plot([0, 7.5], [0.8, 0.8], \"k-\", linewidth=2)\n","plt.plot([0, 7.5], [1.75, 1.75], \"k--\", linewidth=2)\n","plt.text(1.0, 0.9, \"Depth=0\", fontsize=15)\n","plt.text(1.0, 1.80, \"Depth=1\", fontsize=13)\n","\n","plt.show()"],"metadata":{"id":"pZPaEcqCBDjT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ejercicio"],"metadata":{"id":"w0vydmHSB3Ka"}},{"cell_type":"markdown","source":["La principal actividad de esta práctica es entrenar un modelo de clasificación usando unos datos de Kaggle. En primer lugar, entren a la [siguiente liga](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database) y descargen los datos para después subirlos al entorno de programación en Google Colab."],"metadata":{"id":"Vyfu0sd_B5Ai"}},{"cell_type":"markdown","source":["**Actividad 1** : Describir el conjunto de datos que acaban de descargar.\n","\n","- ¿Sobre qué trata este conjunto de datos? ¿Que intenta predecir?\n","- ¿Cuántas características tiene cada dato? Escribir una breve descripción de cada una de ellas."],"metadata":{"id":"vlmWjIslCRsw"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score"],"metadata":{"id":"c3wPmDrRDgJ9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para empezar el flujo de trabajo, vamos a cargar los datos en un `DataFrame` de Pandas usando la función `read_csv`."],"metadata":{"id":"vFclsskhG6ak"}},{"cell_type":"code","source":["df = pd.read_csv(\"diabetes.csv\")"],"metadata":{"id":"W_hGJ940Fw6-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Nunca está de más verificar que todo se cargó sin problemas con el método `head()`."],"metadata":{"id":"bZIr82goC_6N"}},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"BtMH8FbhG3F3","executionInfo":{"status":"ok","timestamp":1702704001617,"user_tz":360,"elapsed":137,"user":{"displayName":"Luis Zúñiga","userId":"03667980173351348064"}},"outputId":"8ae827c9-74c0-479e-f29d-adeb56880b25"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n","0            6      148             72             35        0  33.6   \n","1            1       85             66             29        0  26.6   \n","2            8      183             64              0        0  23.3   \n","3            1       89             66             23       94  28.1   \n","4            0      137             40             35      168  43.1   \n","\n","   DiabetesPedigreeFunction  Age  Outcome  \n","0                     0.627   50        1  \n","1                     0.351   31        0  \n","2                     0.672   32        1  \n","3                     0.167   21        0  \n","4                     2.288   33        1  "],"text/html":["\n","  <div id=\"df-a3ec2339-4371-4f9e-a61b-34d82b6f60d1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3ec2339-4371-4f9e-a61b-34d82b6f60d1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a3ec2339-4371-4f9e-a61b-34d82b6f60d1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a3ec2339-4371-4f9e-a61b-34d82b6f60d1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-05de4aeb-e9a2-4ce8-b0e5-bdbd7cf781ae\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-05de4aeb-e9a2-4ce8-b0e5-bdbd7cf781ae')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-05de4aeb-e9a2-4ce8-b0e5-bdbd7cf781ae button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["Vamos a preparar los datos para el modelo partiendolos en un conjunto de prueba y uno de entrenamiento:"],"metadata":{"id":"XZsvh9EYPCQT"}},{"cell_type":"code","source":["feature_cols = ['pregnancies', 'glucose', 'bp', 'skinthickness','insulin','bmi','pedigree','age']\n","X = df.drop(['Outcome'], axis=1) # caracteristicas (todas salvo la columna 'outcome')\n","y = df['Outcome'] # variable objetivo ('outcome')"],"metadata":{"id":"FV5G6syCIHdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creamos los conjunto de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"],"metadata":{"id":"JlacOLH1JUy2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ahora vamos a crear nuestro modelo de clasificación, un AD para clasificación:"],"metadata":{"id":"cTw84xlEPIpN"}},{"cell_type":"code","source":["# creamos el modelo de clasificacion\n","clf = DecisionTreeClassifier()\n","\n","# entrenamos el modelo con nuestros datos de entrenamiento X_test y y_test\n","clf = clf.fit(X_train,y_train)\n","\n","# realizamos las prediciones de X_test\n","y_pred = clf.predict(X_test)"],"metadata":{"id":"vSk_8lm2JyAx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos a evaluar el rendimiento del modelo usando la medida F1"],"metadata":{"id":"zlnLhdi_D8QE"}},{"cell_type":"code","source":["# Model Accuracy, how often is the classifier correct?\n","print(f\"F1 score: {f1_score(y_test, y_pred)}\", )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PyfbAsRqJ1AN","executionInfo":{"status":"ok","timestamp":1702704032417,"user_tz":360,"elapsed":122,"user":{"displayName":"Luis Zúñiga","userId":"03667980173351348064"}},"outputId":"465dbc1b-94e5-4123-9c3b-713b87d56e58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 score: 0.5925925925925926\n"]}]},{"cell_type":"markdown","source":["Como en los casos anteriores, vamos a visualizar el árbol y contemplar nuestro modelo entrenado:"],"metadata":{"id":"ybwcpuMXMciv"}},{"cell_type":"code","source":["from sklearn.tree import export_graphviz\n","from six import StringIO\n","from IPython.display import Image\n","import pydotplus\n","\n","dot_data = StringIO()\n","export_graphviz(clf, out_file=dot_data,\n","                filled=True, rounded=True,\n","                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n","graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n","graph.write_png('diabetes.png')\n","Image(graph.create_png())"],"metadata":{"id":"b5CzYBqDKeBA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["¡Vaya! Está horrible. Bueno, es lo que salió. Problemas complejos requieren árboles complejos, ¿no creen? Bien, el único detalle que se omotió (por fines educativos) es la regularización del modelo."],"metadata":{"id":"5S1wm3j4EnyE"}},{"cell_type":"markdown","source":["**Actividad #2**: Vamos a medir el efecto que tiene el parámetro `max_depth` en la métrica de evaluación. Construir la gráfica de max_depth vs F1 score, con max_depth tomando valores desde 1 hasta 20. Para el modelo, utilizar como criterio `entropy`."],"metadata":{"id":"B1pMgtnmN7p_"}},{"cell_type":"markdown","source":["**Actividad #3**: Repetir la actividad anterior pero con otro parámetro que se discutió en la sección de regularización que no sea `max_depth`."],"metadata":{"id":"jiyFeqp3FbZi"}}]}